"""æ ¸å¿ƒ Agent ç±»"""
from typing import List, Dict, Optional
from kimi_client import KimiClient
from tools import SearchTool, AnalysisTool, EducationKnowledgeBase
from config import Config


class EducationAgent:
    """ä¸­å°å­¦æ•™å­¦åŠ©æ‰‹ Agent"""
    
    def __init__(self):
        self.llm = KimiClient()
        self.search_tool = SearchTool()
        self.analysis_tool = AnalysisTool()
        self.knowledge_base = EducationKnowledgeBase()
        self.conversation_history = []
    
    def plan(self, question: str) -> List[str]:
        """
        è§„åˆ’è§£å†³æ­¥éª¤
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
        
        Returns:
            è§„åˆ’æ­¥éª¤åˆ—è¡¨
        """
        print(f"\nğŸ“‹ æ­£åœ¨è§„åˆ’é—®é¢˜ï¼š{question}")
        steps = self.llm.plan(question)
        print(f"âœ… è§„åˆ’å®Œæˆï¼Œå…± {len(steps)} ä¸ªæ­¥éª¤ï¼š")
        for i, step in enumerate(steps, 1):
            print(f"  {i}. {step}")
        return steps
    
    def retrieve(self, question: str, step: str) -> Optional[str]:
        """
        æ£€ç´¢ç›¸å…³ä¿¡æ¯
        
        Args:
            question: åŸå§‹é—®é¢˜
            step: å½“å‰æ­¥éª¤
        
        Returns:
            æ£€ç´¢åˆ°çš„ä¿¡æ¯
        """
        print(f"\nğŸ” æ­£åœ¨æ£€ç´¢ï¼š{step}")
        
        # 1. å…ˆæœç´¢çŸ¥è¯†åº“
        kb_result = self.knowledge_base.search(question)
        if kb_result:
            print(f"  âœ“ ä»çŸ¥è¯†åº“æ‰¾åˆ°ç›¸å…³ä¿¡æ¯")
            return kb_result
        
        # 2. ç½‘ç»œæœç´¢
        search_results = self.search_tool.search(question)
        if search_results:
            print(f"  âœ“ æ‰¾åˆ° {len(search_results)} æ¡æœç´¢ç»“æœ")
            # åˆå¹¶æœç´¢ç»“æœ
            snippets = [r.get("snippet", "") for r in search_results]
            return "\n".join(snippets)
        
        print(f"  âš  æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯")
        return None
    
    def analyze(self, question: str, context: Optional[str] = None) -> str:
        """
        åˆ†æå¹¶ç”Ÿæˆå›ç­”
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            context: æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡
        
        Returns:
            åˆ†æç»“æœ
        """
        print(f"\nğŸ§  æ­£åœ¨åˆ†æé—®é¢˜...")
        answer = self.llm.analyze(question, context)
        print(f"âœ… åˆ†æå®Œæˆ")
        return answer
    
    def execute_step(self, question: str, step: str, iteration: int) -> Dict:
        """
        æ‰§è¡Œå•ä¸ªæ­¥éª¤
        
        Args:
            question: åŸå§‹é—®é¢˜
            step: å½“å‰æ­¥éª¤
            iteration: è¿­ä»£æ¬¡æ•°
        
        Returns:
            æ­¥éª¤æ‰§è¡Œç»“æœ
        """
        print(f"\n{'='*50}")
        print(f"æ­¥éª¤ {iteration}: {step}")
        print(f"{'='*50}")
        
        # æ£€ç´¢ä¿¡æ¯
        context = self.retrieve(question, step)
        
        # åˆ†æé—®é¢˜
        if "æ£€ç´¢" in step or "æœç´¢" in step or "æŸ¥æ‰¾" in step:
            # å¦‚æœæ˜¯æ£€ç´¢æ­¥éª¤ï¼Œå…ˆæ£€ç´¢å†åˆ†æ
            analysis = self.analyze(question, context)
        else:
            # å…¶ä»–æ­¥éª¤ç›´æ¥åˆ†æ
            analysis = self.analyze(f"{question}\n\nå½“å‰æ­¥éª¤ï¼š{step}", context)
        
        return {
            "step": step,
            "context": context,
            "analysis": analysis,
            "iteration": iteration
        }
    
    def run(self, question: str) -> Dict:
        """
        è¿è¡Œ Agent å¤„ç†é—®é¢˜
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
        
        Returns:
            å®Œæ•´çš„ç»“æœ
        """
        print(f"\n{'='*60}")
        print(f"ğŸ“ ä¸­å°å­¦æ•™å­¦åŠ©æ‰‹ Agent")
        print(f"{'='*60}")
        print(f"é—®é¢˜ï¼š{question}\n")
        
        # 1. è§„åˆ’
        steps = self.plan(question)
        
        if not steps:
            return {
                "question": question,
                "error": "è§„åˆ’å¤±è´¥"
            }
        
        # 2. æ‰§è¡Œæ­¥éª¤
        results = []
        for i, step in enumerate(steps, 1):
            if i > Config.MAX_ITERATIONS:
                print(f"\nâš ï¸ è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°é™åˆ¶")
                break
            
            result = self.execute_step(question, step, i)
            results.append(result)
            
            # å¦‚æœå·²ç»å¾—åˆ°è¶³å¤Ÿä¿¡æ¯ï¼Œå¯ä»¥æå‰ç»“æŸ
            if result.get("analysis"):
                # å¯ä»¥æ·»åŠ æå‰ç»ˆæ­¢é€»è¾‘
                pass
        
        # 3. ç»¼åˆæ‰€æœ‰ç»“æœç”Ÿæˆæœ€ç»ˆå›ç­”
        print(f"\n{'='*60}")
        print(f"ğŸ“ ç”Ÿæˆæœ€ç»ˆå›ç­”...")
        print(f"{'='*60}")
        
        # æ±‡æ€»æ‰€æœ‰åˆ†æç»“æœ
        all_context = "\n\n".join([
            f"æ­¥éª¤ {r['iteration']}: {r['step']}\nåˆ†æï¼š{r['analysis']}"
            for r in results if r.get("analysis")
        ])
        
        final_answer = self.analyze(question, all_context)
        
        return {
            "question": question,
            "steps": steps,
            "results": results,
            "final_answer": final_answer
        }
    
    def chat(self, question: str) -> str:
        """
        ç®€å•å¯¹è¯æ¥å£ï¼ˆç›´æ¥å›ç­”ï¼Œä¸è¿›è¡Œå¤æ‚è§„åˆ’ï¼‰
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
        
        Returns:
            å›ç­”
        """
        # å…ˆå°è¯•ä»çŸ¥è¯†åº“æ£€ç´¢
        context = self.knowledge_base.search(question)
        
        # å¦‚æœçŸ¥è¯†åº“æ²¡æœ‰ï¼Œè¿›è¡Œç½‘ç»œæœç´¢
        if not context:
            search_results = self.search_tool.search(question)
            if search_results:
                context = "\n".join([r.get("snippet", "") for r in search_results])
        
        # ä½¿ç”¨ LLM ç”Ÿæˆå›ç­”
        answer = self.llm.analyze(question, context)
        return answer
